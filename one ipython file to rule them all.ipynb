{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing really useful stuff\n",
    "import rebound\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from math import log10, floor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SECTION 1 - finding transit timing variations with various parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Section 1.0: finding and removing all unstable systems\n",
    "\n",
    "Unstable systems will result in significantly increased transit timing variations, which could skew the averaged data. \n",
    "\n",
    "The critical a value (semi-major axis) for \"venus\" was determined to the value when the aphelion of \"venus\"'s orbit woukd cross with the perihelion of \"earth\"'s orbit for each value of 'e' (eccentricity). \n",
    "\n",
    "a_venus(1 + e_venus) = a_earth(1 - e_earth) --> a_venus = 1(1 - 0.05)/1 + e_venus\n",
    "\n",
    "This ruled out a number of cases. However. there were still many unstable orbits on the boundary of that line (imagine a 2-dimensional graph with 'e' represented on the x axis and 'a' on the y axis', with the line represented at a=0.95/1+e). \n",
    "\n",
    "Due to this we ran trial cases (running the orbit systems for 100,000 years with the minimum exit distance set as 0.05 AU) for e = 0.05, e=0.1, e=0.15 and e=0.2. All cases for 'a' were run starting with a = 0.85 and running until there were 7-16 stable cases in a row. 'f' (anomaly) and 'omega' (location of particle) were randomized for each case between 0.0 and 2pi, which is why many stable orbits had to be seen in a row. the lowest percent of the critical a value which was a boundary for stable vs unstable cases was found to be ~0.94 (in other words, all cases lower than 0.94 x 'a crit' for each 'e' value were stable). the cutoff for running ttv variations was set to 0.93 x 'a crit'. all cases that remained with transit variation (in hours) greater than 9 hours were retested (running the orbit system for 100,000 years, minimum exit distance also 0.05 AU) and all were shown to be stable without exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#defining how to find TTV\n",
    "\n",
    "def runsimulation():\n",
    "    \n",
    "    #setup simulation\n",
    "    sim = rebound.Simulation()\n",
    "    sim.integrator = \"ias15\"\n",
    "    sim.exit_min_distance = 0.05 #if the two particles (\"earth\" and \"venus\") reach within 0.05AU of each other, a rebound.encounter error is shown\n",
    "    sim.add(m=1)\n",
    "    sim.add(m=m_mass, a=a_distance, e=e_eccentricity, f=f_anomaly, omega=omega_locationofparticle)\n",
    "    sim.add(m=3e-6, a=1,e=0.05,omega=0.25)\n",
    "    sim.move_to_com()\n",
    "     \n",
    "    \n",
    "    stable = True\n",
    "    if a_distance*(1+e_eccentricity) < 1*(1-0.05): #a(1-e) for earth. if the aphelion of venus is less than the perihelion of earth, otherwise assume they're going to be unstable as the orbits cross\n",
    "        print(\"running\")\n",
    "        nyears = 100000 #number of years the program runs for\n",
    "        noutput = 10 #number of total steps, doesn't matter because the program checks every timestep anyways, this just sets an amount of time to integrate for\n",
    "        times = np.linspace(0,nyears*2*np.pi,noutput)\n",
    "        min_distance = 5\n",
    "        distances = np.zeros(noutput)\n",
    "        try:\n",
    "            for i,time in enumerate(times):\n",
    "                sim.integrate(time)\n",
    "        except rebound.Encounter as error:\n",
    "            print(a_distance, f_anomaly, omega_locationofparticle, \"UNSTABLE\") #important to print f and omega because they are randomized\n",
    "            stable = False\n",
    "    else: #if the orbits cross\n",
    "        stable = False\n",
    "        print(a_distance, \"unstable. case omitted: orbits cross.\")\n",
    "        \n",
    "    if stable == True:\n",
    "        print(a_distance, f_anomaly, omega_locationofparticle, \"STABLE\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#change parameters\n",
    "import numpy as np\n",
    "import random\n",
    "m_mass = 2.45e-6\n",
    "e_eccentricity = 0.05 #0.10, 0.15, 0.20 \n",
    "for i in range(85):\n",
    "    a_distance = 0.85 - i*0.0015\n",
    "    f_anomaly = random.uniform(0, 2*np.pi) #chooses a random value between 0 and 2pi\n",
    "    omega_locationofparticle = random.uniform(0, 2*np.pi)\n",
    "    runsimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Section 1.1: running all systems and finding transit timing variations\n",
    "\n",
    "with 'a' running from 0.7-0.85 AU, 'e' from 0.0-0.2, and 'f' and 'omega' from 0.0-2pi, each system was run for 19 years (4 years kepler, 11 years pause, 4 years mission). these 19 variations along with the 'a' and 'e' of each case were recorded in a file (ttvdata2.txt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ttvdata = open(\"ttvdata.txt\", \"w+\")  #currently the data is actually stored in ttvdata2.txt\n",
    "ttvdata.close()\n",
    "\n",
    "def ttv():\n",
    "    #setup simulation\n",
    "    sim = rebound.Simulation()\n",
    "    sim.add(m=1) #this is the sun\n",
    "    sim.add(m=m_mass, a=a_distance, e=e_eccentricity, f=f_anomaly, omega=omega_locationofparticle) #\"venus\", whatever parameters are currently running\n",
    "    sim.add(m=3e-6, a=1,e=0.05,omega=0.25)\n",
    "    sim.move_to_com()\n",
    "    p = sim.particles\n",
    "    \n",
    "    addtottv = True\n",
    "    \n",
    "    #code below is not mine, from hannorein?\n",
    "\n",
    "    #find individual time of intersection N times\n",
    "    N=19\n",
    "    transittimes = np.zeros(N)\n",
    "    i = 0\n",
    "    while i<N:\n",
    "        y_old = p[2].y - p[0].y  \n",
    "        t_old = sim.t\n",
    "        sim.integrate(sim.t+0.5) # check for transits every 0.5 time units. Note that 0.5 is shorter than one orbit\n",
    "        t_new = sim.t\n",
    "        if y_old*(p[2].y-p[0].y)<0. and p[2].x-p[0].x>0.:   # sign changed (y_old*y<0), planet in front of star (x>0)\n",
    "            while t_new-t_old>1e-7:   # bisect until prec of 1e-5 reached\n",
    "                if y_old*(p[2].y-p[0].y)<0.:\n",
    "                    t_new = sim.t\n",
    "                else:\n",
    "                    t_old = sim.t\n",
    "                sim.integrate( (t_new+t_old)/2.)\n",
    "            transittimes[i] = sim.t\n",
    "            i += 1\n",
    "            sim.integrate(sim.t+0.05)  \n",
    "\n",
    "    \n",
    "    #remove linear trend\n",
    "    A = np.vstack([np.ones(N), range(N)]).T\n",
    "    c, m = np.linalg.lstsq(A, transittimes)[0]  \n",
    "    \n",
    "    \n",
    "    if a_distance > 0.93*(0.95/1+e_eccentricity):\n",
    "        addtottv = False\n",
    "\n",
    "    def round_sig(x, sig=2):\n",
    "        return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "    #if orbits are stable, adds the transit variations to a .txt file\n",
    "    if addtottv == True:\n",
    "        #store values in variable called temp. then convert to tempvconvert (each variation on indv. line, 4 sig. figs.)\n",
    "        temp = (transittimes-m*np.array(range(N))-c)*(24.*365./2./np.pi);\n",
    "        tempconvert = \"\\n\" + str(a_distance) + \"\\n\" + str(e_eccentricity)\n",
    "        for i in range(len(temp)):\n",
    "            tempconvert = tempconvert + \"\\n\" + str(round_sig(temp[i], 4))\n",
    "    \n",
    "        #add tempconvert data to a .txt file\n",
    "        ttvdata = open(\"ttvdata.txt\",\"a+\") \n",
    "        ttvdata.write(tempconvert)\n",
    "        ttvdata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#MAIN (running parameters)\n",
    "a_distance_min = 0.7\n",
    "a_distance_max = 0.85\n",
    "a_distance_total_steps = 100\n",
    "a_distance_step = (a_distance_max - a_distance_min)/a_distance_total_steps\n",
    "\n",
    "e_eccentricity_min = 0.0\n",
    "e_eccentricity_max = 0.2\n",
    "e_eccentricity_total_steps = 5 \n",
    "e_eccentricity_step = (e_eccentricity_max - e_eccentricity_min)/e_eccentricity_total_steps\n",
    "\n",
    "f_anomaly_min = 0.0\n",
    "f_anomaly_max = 2*np.pi\n",
    "f_anomaly_total_steps = 10\n",
    "f_anomaly_step = (f_anomaly_max - f_anomaly_min)/f_anomaly_total_steps\n",
    "\n",
    "omega_locationofparticle_min = 0.0\n",
    "omega_locationofparticle_max = 2*np.pi\n",
    "omega_locationofparticle_total_steps = 10\n",
    "omega_locationofparticle_step = (omega_locationofparticle_max - omega_locationofparticle_min)/omega_locationofparticle_total_steps\n",
    "\n",
    "m_mass = 2.45e-6\n",
    "for i in range(a_distance_total_steps):\n",
    "    a_distance = a_distance_min + i*a_distance_step \n",
    "    for j in range(e_eccentricity_total_steps):\n",
    "        e_eccentricity = e_eccentricity_min + j*e_eccentricity_step\n",
    "        for k in range(f_anomaly_total_steps): \n",
    "            f_anomaly = f_anomaly_min + k*f_anomaly_step\n",
    "            for l in range(omega_locationofparticle_total_steps):\n",
    "                omega_locationofparticle = omega_locationofparticle_min + l*omega_locationofparticle_step\n",
    "                ttv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SECTION 2 - finding delta SNR between light transits with and without transit timing variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "section 2.0: Retrieving yearly transit timing variation data\n",
    "The transit variation data from the file was read. Only the first 4 and last 4 variations of the 19 years was stored in an array (accounting for the missing 11 years). both 'a' and 'e' for each case were stored too for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the file containing the simulation and transit timing variations is opened and the information is added to a list\n",
    "file1 = open('ttvdata.txt', 'r') \n",
    "mylist1 = file1.readlines() #adds all lines of txt file to list\n",
    "\n",
    "#list 2 is created to strip each element of list1 of 'n' and any unneeded spaces\n",
    "mylist2 = []\n",
    "for i in range(len(mylist1)):\n",
    "    mylist2.append(mylist1[i].strip())\n",
    "mylist2.pop(0) \n",
    "#^^removes first element of list, which is an empty line (just happens to be the case in the particular text file)\n",
    "\n",
    "#here another list is created to float each element of list2, which were strings\n",
    "mylist3 = []\n",
    "for i in range(len(mylist2)):\n",
    "    mylist3.append(float(mylist2[i]))\n",
    "\n",
    "#this create a 2-dimensional array containing the amount of cases and 21 elements each, inside which each of \n",
    "#the variations will be stored to use later\n",
    "ttvarrayfake = np.zeros((len(mylist3)/21, 21))\n",
    " \n",
    "#here, each of the elements in the list (the transit timing variations) are split up into cases (based on parameters)\n",
    "#and assigned one of ten spots (corresponding to the year in the simulation they occured)\n",
    "count = 0\n",
    "for i in range(len(mylist3)/21): \n",
    "    for j in range(21): #used to be 19\n",
    "        ttvarrayfake[i,j] = mylist3[count]\n",
    "        count = count+1\n",
    "        \n",
    "ttvarray = np.zeros((len(mylist3)/21,10))\n",
    "        \n",
    "#removes the 11 years for which we do not have data (5-15 inclusive), first two are a and e\n",
    "for i in range(len(mylist3)/21):\n",
    "    for b in range(2):\n",
    "        ttvarray[i,b] = ttvarrayfake[i,b]\n",
    "    for k in range(4):\n",
    "        ttvarray[i,2+k] = ttvarrayfake[i,2+k]\n",
    "    for p in range(4):\n",
    "        ttvarray[i,6+p]= ttvarrayfake[i,17+p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "a model of light levels (0=normal) was drawn for the \"sun\" over the course of 8 years for both a system without venus and a system with \"venus\". random noise (with blah blah blah of 5e-5?) was created (same noise was used for both cases). these 8 years were then averaged into one year, shallowing out the \"box\"\n",
    "\n",
    "a box model was created to find the best fit. the box model ran through a _?_ grid of depths and distances to find the box model with the smallest chi square to the averaged data of the 8 years plotted over one year (shallowed out)\n",
    "\n",
    "this best fitting box model was then used to fin the SNR for both venus and without venus for each case, using the formula ____ . a, e and delta snr for each case were then stored in an array and finally copied over to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def findbox():\n",
    "    #create an array that contains all the average values throughout a year\n",
    "    averagesarray = np.zeros(int(halfhoursinyear))\n",
    "    averagesarray1 = np.zeros(int(halfhoursinyear))\n",
    "    for a in range(halfhoursinyear): \n",
    "        tempaverage = 0\n",
    "        tempaverage1 = 0\n",
    "        for b in range(numberofyears):\n",
    "            tempaverage = tempaverage + myarray[b,1,a]\n",
    "            tempaverage1 = tempaverage1 + myarray1[b,1,a]\n",
    "        averagesarray[a] = tempaverage/numberofyears\n",
    "        averagesarray1[a] = tempaverage1/numberofyears\n",
    "        \n",
    "    #create an initial value for setfit, for which tempfit will be lower\n",
    "    setfit=10e10\n",
    "    setfit1 =10e10\n",
    "    \n",
    "    #set boxarray variables to global so other segments can access the information. create a boxarray to represent the box\n",
    "    global boxarray\n",
    "    global boxarray1\n",
    "    \n",
    "    boxarray = np.zeros(int(halfhoursinyear))\n",
    "    boxarray1 = np.zeros(int(halfhoursinyear))\n",
    "    \n",
    "    global tempdistance, tempdistance1\n",
    "    global tempdepth, tempdepth1\n",
    "    \n",
    "    #try different variations of depth/distance (distance = transit duration) of the box\n",
    "    depth_run = 40\n",
    "    depth_min=0.4\n",
    "    depth_max=1.2\n",
    "    depth_step=(depth_max-depth_min)/depth_run\n",
    "    distance_run = 40  \n",
    "    distance_min=0.5\n",
    "    distance_max=3\n",
    "    distance_step=(distance_max-distance_min)/distance_run\n",
    "    for i in range(depth_run):\n",
    "        tempdepth = (depth_min + depth_step*i)*depthoftransit \n",
    "        for j in range(distance_run):\n",
    "            tempdistance = (distance_min + distance_step*j)*transitduration\n",
    "            \n",
    "            trybox()\n",
    "           \n",
    "            mylist = np.zeros(halfhoursinyear)\n",
    "            mylist1 = np.zeros(halfhoursinyear)\n",
    "            \n",
    "            mylist = testarray - averagesarray\n",
    "            mylist1 = testarray - averagesarray1\n",
    "            \n",
    "            \n",
    "            tempfit = np.sum(mylist**2)\n",
    "            tempfit1 = np.sum(mylist1**2)\n",
    "            \n",
    "            if tempfit < setfit:\n",
    "                setfit = tempfit\n",
    "                setdepth = tempdepth\n",
    "                setdistance = tempdistance\n",
    "                boxarray = testarray\n",
    "                \n",
    "            if tempfit1 < setfit1:\n",
    "                setfit1 = tempfit1\n",
    "                setdepth1 = tempdepth\n",
    "                setdistance1 = tempdistance\n",
    "                boxarray1 = testarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def trybox():\n",
    "    global testarray\n",
    "    \n",
    "    testarray = np.zeros(int(halfhoursinyear))\n",
    "    \n",
    "    #creates a beautiful box\n",
    "    ta_midpoint = midpoint\n",
    "    ta_tempsp = ta_midpoint - tempdistance/2\n",
    "    ta_tempep = ta_midpoint + tempdistance/2\n",
    "    \n",
    "    ta_decimalsp = ta_tempsp - int(ta_tempsp)\n",
    "    ta_decimalep = ta_tempep - int(ta_tempep)\n",
    "\n",
    "    #using the cutoff between bins as ?.5. for example, if the transit was found to start at hour 25.4, the bin of\n",
    "    #light for 25 would be set to 0.9 and for 26 would be set to full value.\n",
    "    if ta_decimalsp > 0.50:\n",
    "        ta_sp = int(ta_tempsp)+2 #start point of full value transits\n",
    "        ta_percentsp = 1 - (ta_decimalsp - 0.50)\n",
    "        ta_beforesp = int(ta_tempsp)+1 #the start point that doesn't have full value\n",
    "        testarray[ta_beforesp] = 0 - tempdepth*ta_percentsp\n",
    "    elif ta_decimalsp < 0.50:\n",
    "        ta_sp = int(ta_tempsp)+1\n",
    "        ta_percentsp = 1 - (0.50-ta_decimalsp)\n",
    "        ta_beforesp = int(ta_tempsp)\n",
    "        testarray[ta_beforesp] = 0 - tempdepth*ta_percentsp\n",
    "     \n",
    "    if ta_decimalep < 0.50:\n",
    "        ta_ep = int(ta_tempep)-1\n",
    "        ta_percentep = 1 - (0.50-ta_decimalep)\n",
    "        ta_afterep = int(ta_tempep)\n",
    "        testarray[ta_afterep] = 0 - tempdepth*ta_percentep\n",
    "    if ta_decimalep > 0.50:\n",
    "        ta_ep = int(ta_tempep)\n",
    "        ta_percentep = 1 - (ta_decimalep - 0.50)\n",
    "        ta_afterep = int(ta_tempep)+1\n",
    "        testarray[ta_afterep] = 0 - tempdepth*ta_percentep\n",
    "\n",
    "    #endpoint-startpoint + 1(to be inclusive)\n",
    "    ta_actual_length_of_transit = ta_ep-ta_sp+1 \n",
    "        \n",
    "    #the non-full transit depths have been set, here the full transit depths are set\n",
    "    for z in range(ta_actual_length_of_transit):\n",
    "        testarray[ta_sp+z] = 0 - tempdepth\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#now run everything\n",
    "casenumbers = len(ttvarray)\n",
    "\n",
    "#will contain a, e and delta SNR\n",
    "valuesarray = np.zeros((casenumbers,3))\n",
    "\n",
    "for cn in range(casenumbers):\n",
    "    numberofyears = 8\n",
    "    lengthoforbit = 1\n",
    "    transitduration = 12.9791194828*2 #in half hours\n",
    "    midpoint = 50 #halfhours\n",
    "    halfhoursinyear = 17520*lengthoforbit\n",
    "    depthoftransit = 0.00008389575\n",
    "    sigma = 1*(5e-5)\n",
    "\n",
    "    myarray = np.zeros((numberofyears,2,int(halfhoursinyear)))\n",
    "    myarray1 = np.zeros((numberofyears,2,int(halfhoursinyear)))\n",
    "    #seperated by number of years (0=1-9=10), time=0, light=1\n",
    "    \n",
    "    withoutvenusarray = np.zeros(int(halfhoursinyear)) #creates an array with one space for each bin in the number of years\n",
    "    withvenusarray = np.zeros(int(halfhoursinyear)) #creates another one, this one for with ttv\n",
    "\n",
    "    randomnoisearray = np.zeros((numberofyears, int(halfhoursinyear)))\n",
    "    \n",
    "    for i in range(numberofyears):\n",
    "        \n",
    "        #Section 2.2: creating the light levels over the course of 8 years\n",
    "       \n",
    "        #RUN WITHOUT VENUS VARIATIONS\n",
    "        #setting all time to increase by 1/17520th of a year (half hour) increments within the period of each year\n",
    "        for j in range(len(myarray1[i,0])):\n",
    "            myarray1[i,0,j]= 0 + j*0.5    #0.00005707762\n",
    "   \n",
    "        #setting all light levels = 1 (mean) \n",
    "        for k in range(len(myarray1[i,1])):\n",
    "                myarray1[i,1,k]=0\n",
    "\n",
    "        #subtracting the light decrease resulting from transit\n",
    "        ttvsp1 = midpoint - transitduration/2 #transit start point\n",
    "        ttvep1 = midpoint + transitduration/2 #transit end point\n",
    "        \n",
    "       \n",
    "        decimalsp1 = (ttvsp1 - int(ttvsp1))\n",
    "        decimalep1 = (ttvep1 - int(ttvep1))\n",
    "        \n",
    "        #basically determines which side of the 0.5 boundary the start point and end point \n",
    "        #are and therefore which bin/half hour is the start of the full transit and which might have some \n",
    "        #fractional transit\n",
    "        if decimalsp1 > 0.50:\n",
    "            sp1 = int(ttvsp1)+2 #start point of full value transits\n",
    "            percentsp1 = 1 - (decimalsp1 - 0.50)\n",
    "            beforesp1 = int(ttvsp1)+1 #the start point that doesn't have full value\n",
    "            myarray1[i, 1, beforesp1] = myarray1[i,1,beforesp1] - depthoftransit*percentsp1\n",
    "        elif decimalsp1 < 0.50:\n",
    "            sp1 = int(ttvsp1)+1\n",
    "            percentsp1 = 1 - (0.50-decimalsp1)\n",
    "            beforesp1 = int(ttvsp1)\n",
    "            myarray1[i, 1, beforesp1] = myarray1[i,1,beforesp1] - depthoftransit*percentsp1\n",
    "        \n",
    "        if decimalep1 < 0.50:\n",
    "            ep1 = int(ttvep1)-1\n",
    "            percentep1 = 1 - (0.50-decimalep1)\n",
    "            afterep1 = int(ttvep1)\n",
    "            myarray1[i, 1, afterep1] = myarray1[i,1,afterep1] - depthoftransit*percentep1\n",
    "        if decimalep1 > 0.50:\n",
    "            ep1 = int(ttvep1)\n",
    "            percentep1 = 1 - (decimalep1 - 0.50)\n",
    "            afterep1 = int(ttvep1)+1\n",
    "            myarray1[i, 1, afterep1] = myarray1[i,1,afterep1] - depthoftransit*percentep1\n",
    "        \n",
    "        actual_length_of_transit1 = ep1-sp1+1\n",
    "        \n",
    "        for z in range(actual_length_of_transit1):\n",
    "            myarray1[i,1,sp1+z] = myarray1[i,1,sp1+z] - depthoftransit\n",
    "\n",
    "        #adding noise\n",
    "        for m in range(len(myarray1[i,1])):\n",
    "            randomnoisearray[i,m] = np.random.normal(0,sigma) #mean is 1, range of distribution is 0.00005 either direction (e-5)\n",
    "            myarray1[i,1,m] = myarray1[i,1,m] + randomnoisearray[i,m]\n",
    "\n",
    "        \n",
    "        #RUN WITH VENUS VARIATIONS\n",
    "        #setting all time to increase by 1/17520th of a year (half hour) increments within the period of each year\n",
    "        for j in range(len(myarray[i,0])):\n",
    "            myarray[i,0,j]= 0 + j*0.5    #0.00005707762\n",
    "       \n",
    "        #setting all light levels = 0 (mean) \n",
    "        for k in range(len(myarray[i,1])):\n",
    "                myarray[i,1,k]=0\n",
    "\n",
    "        #subtracting the light decrease resulting from transit\n",
    "        ttvmidpoint = midpoint + ttvarray[cn, 2+i] #changed it because the first two values are a and e\n",
    "\n",
    "        ttvsp = ttvmidpoint - transitduration/2 #transit start point\n",
    "        ttvep = ttvmidpoint + transitduration/2 #transit end point\n",
    "        \n",
    "       \n",
    "        decimalsp = (ttvsp - int(ttvsp))\n",
    "        decimalep = (ttvep - int(ttvep))\n",
    "        \n",
    "        if decimalsp > 0.50:\n",
    "            sp = int(ttvsp)+2 #start point of full value transits\n",
    "            percentsp = 1 - (decimalsp - 0.50)\n",
    "            beforesp = int(ttvsp)+1 #the start point that doesn't have full value\n",
    "            myarray[i, 1, beforesp] = myarray[i,1,beforesp] - depthoftransit*percentsp\n",
    "        elif decimalsp < 0.50:\n",
    "            sp = int(ttvsp)+1\n",
    "            percentsp = 1 - (0.50-decimalsp)\n",
    "            beforesp = int(ttvsp)\n",
    "            myarray[i, 1, beforesp] = myarray[i,1,beforesp] - depthoftransit*percentsp\n",
    "        \n",
    "        \n",
    "        if decimalep < 0.50:\n",
    "            ep = int(ttvep)-1\n",
    "            percentep = 1 - (0.50-decimalep)\n",
    "            afterep = int(ttvep)\n",
    "            myarray[i, 1, afterep] = myarray[i,1,afterep] - depthoftransit*percentep\n",
    "        if decimalep > 0.50:\n",
    "            ep = int(ttvep)\n",
    "            percentep = 1 - (decimalep - 0.50)\n",
    "            afterep = int(ttvep)+1\n",
    "            myarray[i, 1, afterep] = myarray[i,1,afterep] - depthoftransit*percentep\n",
    "        \n",
    "        actual_length_of_transit = ep-sp+1\n",
    "        \n",
    "        for z in range(int(actual_length_of_transit)):\n",
    "            myarray[i,1,sp+z] = myarray[i,1,sp+z] - depthoftransit\n",
    "        \n",
    "    \n",
    "        midpoint = midpoint + halfhoursinyear - int(halfhoursinyear)\n",
    "\n",
    "        #adding noise\n",
    "        for m in range(len(myarray[i,1])):\n",
    "            myarray[i,1,m] = myarray[i,1,m] + randomnoisearray[i,m]\n",
    "          \n",
    "    \n",
    "    #SECTION 2.3: finding the best fitting box model. finds the depth and distance(transit duration) of a box that \n",
    "    #has the lowest chi square of an array \n",
    "    findbox()\n",
    "\n",
    "    #SECTION 2.4: finding signal to noise ratio\n",
    "    for m in range(halfhoursinyear):\n",
    "        withvenusarray[m] = ((0 - boxarray[m])/sigma)**2\n",
    "        withoutvenusarray[m] = ((0 - boxarray1[m])/sigma)**2\n",
    "    \n",
    "    SNR1 = np.sqrt(np.sum(withoutvenusarray))\n",
    "    #print(\"signal to noise ratio without venus\", SNR1)\n",
    "    SNR2 = np.sqrt(np.sum(withvenusarray))\n",
    "    #print(\"   signal to noise ratio with venus\", SNR2)\n",
    "\n",
    "    differenceinsnr = SNR1 - SNR2 #without venus - with venus\n",
    "\n",
    "    #adds a,e and delta SNR to values array\n",
    "    valuesarray[cn,0] = ttvarray[cn,0]\n",
    "    valuesarray[cn,1] = ttvarray[cn,1]\n",
    "    valuesarray[cn, 2] = differenceinsnr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Section 2.5: a, e and delta SNR for each case (recorded in values array) are copied over to valuesarray.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myfile = open(\"valuesarray.txt\", \"w+\") #information actually in valuesarray2.txt\n",
    "myfile.close()\n",
    "\n",
    "myfile = open(\"valuesarray.txt\",\"a+\") \n",
    "for i in range(len(valuesarray)):\n",
    "    tempfile = \"\\n\" + str(valuesarray[i,0]) + \"\\n\" + str(valuesarray[i,1]) + \"\\n\" + str(valuesarray[i,2])\n",
    "    myfile.write(tempfile)\n",
    "\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SECTION 3 - plotting the data in 3d matplotlib scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "both a,e,delta SNR (averaged for each 100 cases with same a and e) and a,e,ttv (averaged for each 100 cases with same a and e) were plotted seperately in two graphs. then the highest ttv was run by itself and averaged over 500 times. the result was 1.7, while the corresponding value of delta SNR was around 1.5. this was done to confirm the abscence of any gross coding error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "file1 = open('valuesarray2.txt', 'r') \n",
    "mylist1 = file1.readlines() #adds all lines of txt file to list\n",
    "\n",
    "#list 2 is created to strip each element of list1 of 'n' and any unneeded spaces\n",
    "mylist2 = []\n",
    "for i in range(len(mylist1)):\n",
    "    mylist2.append(mylist1[i].strip())\n",
    "mylist2.pop(0) \n",
    "#^^removes first element of list, which is an empty line (just happens to be the case in the particular\n",
    "#text file)\n",
    "\n",
    "#here another list is created to float each element of list2, which were strings\n",
    "mylist3 = []\n",
    "for i in range(len(mylist2)):\n",
    "    mylist3.append(float(mylist2[i]))\n",
    "\n",
    "valuesarray = np.zeros((len(mylist3)/3,3))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(mylist3)/3):\n",
    "    valuesarray[i,0] = mylist3[count]\n",
    "    valuesarray[i,1] = mylist3[count+1]\n",
    "    valuesarray[i,2] = mylist3[count+2]\n",
    "    count = count + 3\n",
    "\n",
    "print(valuesarray[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#creates a plot with a, e and SNR average change for each 100 cases with same a and e\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#this commented out section is to produce a figure with not the averaged values (for each same a and e) but for every single case\n",
    "# xlist = []\n",
    "# ylist = []\n",
    "# zlist = []\n",
    "\n",
    "# for i in range(len(valuesarray)):\n",
    "#     xlist.append(valuesarray[i,0])\n",
    "#     ylist.append(valuesarray[i,1])\n",
    "#     zlist.append(valuesarray[i,2])\n",
    "\n",
    "    \n",
    "# ax.scatter(xlist, ylist, zlist, c=np.abs(zlist),cmap=\"YlGn\")\n",
    "\n",
    "# ax.set_xlabel('distance')\n",
    "# ax.set_ylabel('eccentricity')\n",
    "# ax.set_zlabel('delta SNR')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "averagearray = np.zeros((len(valuesarray)/100,3))\n",
    "for k in range(len(averagearray)):\n",
    "    tempzaverage = 0\n",
    "    for i in range(100):\n",
    "        tempzaverage = tempzaverage + valuesarray[k*100+i,2]\n",
    "    tempzaverage = tempzaverage/100\n",
    "    averagearray[k,0] = np.sqrt((valuesarray[k*100,0])**3)\n",
    "    averagearray[k,1] = valuesarray[k*100,1]\n",
    "    averagearray[k,2] = tempzaverage\n",
    "\n",
    "xlist = []\n",
    "ylist = []\n",
    "zlist = []\n",
    "\n",
    "for i in range(len(averagearray)):\n",
    "    xlist.append(averagearray[i,0])\n",
    "    ylist.append(averagearray[i,1])\n",
    "    zlist.append(averagearray[i,2])\n",
    "    \n",
    "p = ax.scatter(xlist, ylist, zlist, c=np.abs(zlist),cmap=\"brg\")\n",
    "\n",
    "fig.colorbar(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#creates a plot with a, e and average abs(ttv change) for each 100 cases with same a and e\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file1 = open('ttvdata2.txt', 'r') \n",
    "mylist1 = file1.readlines() \n",
    "\n",
    "#list 2 is created to strip each element of list1 of 'n' and any unneeded spaces\n",
    "mylist2 = []\n",
    "for i in range(len(mylist1)):\n",
    "    mylist2.append(mylist1[i].strip())\n",
    "mylist2.pop(0) \n",
    "#^^removes first element of list, which is an empty line (just happens to be the case in the particular\n",
    "#text file)\n",
    "\n",
    "#here another list is created to float each element of list2, which were strings\n",
    "mylist3 = []\n",
    "for i in range(len(mylist2)):\n",
    "    mylist3.append(float(mylist2[i]))\n",
    "\n",
    "    \n",
    "ttvarray1 = np.zeros((len(mylist3)/21, 21))\n",
    " \n",
    "count = 0\n",
    "for i in range(len(mylist3)/21): \n",
    "    for j in range(21): \n",
    "        ttvarray1[i,j] = mylist3[count]\n",
    "        count = count+1\n",
    "        \n",
    "ttvarray2 = np.zeros((len(mylist3)/21,10))\n",
    "        \n",
    "#removes the 11 years for which we do not have data (5-15 inclusive), first two are a and e\n",
    "for i in range(len(mylist3)/21):\n",
    "    for b in range(2):\n",
    "        ttvarray2[i,b] = ttvarray1[i,b]\n",
    "    for k in range(4):\n",
    "        ttvarray2[i,2+k] = ttvarray1[i,2+k]\n",
    "    for p in range(4):\n",
    "        ttvarray2[i,6+p]= ttvarray1[i,17+p]\n",
    "\n",
    "        \n",
    "#finding the average of each case\n",
    "ttvarray3 = np.zeros((len(mylist3)/21,3))\n",
    "\n",
    "for i in range(len(ttvarray2)):\n",
    "    ttvarray3[i,0] = ttvarray2[i,0]\n",
    "    ttvarray3[i,1] = ttvarray2[i,1]\n",
    "    ttvaverage = 0\n",
    "    for j in range(8):\n",
    "        ttvaverage = ttvaverage + abs(ttvarray2[i,j+2])\n",
    "    ttvaverage = ttvaverage/8\n",
    "    ttvarray3[i,2] = ttvaverage\n",
    "\n",
    "\n",
    "#finding the average of the 100 cases with same a and e in ttvarray 3\n",
    "ttvarray = np.zeros((len(ttvarray3)/100, 3))\n",
    "\n",
    "for i in range(len(ttvarray3)/100):\n",
    "    ttvarray[i,0] = ttvarray3[i*100,0]\n",
    "    ttvarray[i,1] = ttvarray3[i*100,1]\n",
    "    ttvaverage1 = 0\n",
    "    for j in range(100):\n",
    "        ttvaverage1 = ttvaverage1 + ttvarray3[i*100+j,2]\n",
    "    ttvaverage1 = ttvaverage1/100\n",
    "    ttvarray[i,2] = ttvaverage1\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xlist = []\n",
    "ylist = []\n",
    "zlist = []\n",
    "\n",
    "for i in range(len(ttvarray)):\n",
    "    xlist.append(ttvarray[i,0])\n",
    "    ylist.append(ttvarray[i,1])\n",
    "    zlist.append(ttvarray[i,2])\n",
    "    \n",
    "\n",
    "    \n",
    "p = ax.scatter(xlist, ylist, zlist, c=np.abs(zlist),cmap=\"brg\")\n",
    "\n",
    "fig.colorbar(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "temporary (averaged over 100) of 8.5 hours ttv was 1.70698076211 SNR difference "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
